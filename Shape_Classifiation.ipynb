{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Flux\n",
    "using Symbolics\n",
    "using SphericalHarmonics\n",
    "using CUDA\n",
    "using NNlib\n",
    "using OneHotArrays\n",
    "using MLUtils\n",
    "\n",
    "using Rotations\n",
    "using TensorCast\n",
    "\n",
    "# Disable slow GPU indexing\n",
    "CUDA.allowscalar(false)\n",
    "\n",
    "using BenchmarkTools\n",
    "using ProgressMeter\n",
    "\n",
    "include(\"utils.jl\")\n",
    "include(\"Spherical.jl\")\n",
    "include(\"alt_parallel.jl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "include(\"TFNLayers.jl\")\n",
    "include(\"alt_parallel.jl\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing Basics of Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RLayer{CuArray{Float32, 1, CUDA.Mem.DeviceBuffer}, Vector{Float32}, Float32}(Float32[-0.48342064, -0.5924541, -0.46601388, -0.4184361], Float32[0.0, 1.1666666, 2.3333333, 3.5], 0.875f0)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# testing R\n",
    "centers = range(0f0, 3.5f0; length=4) |> collect\n",
    "r_test = RLayer(centers) |> gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(CuArray{Float32, 3, CUDA.Mem.DeviceBuffer}[], CuArray{Float32, 3, CUDA.Mem.DeviceBuffer}[[-0.36121196 -0.021606624 … 0.20287748 0.41855606; 0.036829777 0.3516178 … -0.5751697 -0.262716; 0.041203 0.24422988 … -0.07556881 -0.031145327; 0.08022238 -0.7771977 … 0.24490415 -0.32765147;;; -0.34861088 0.035238333 … 0.08414009 0.3777876; 0.06861416 0.43490127 … -0.46269113 -0.11485022; -0.07405516 0.116280064 … -0.15479514 -0.1404848; 0.119697616 -0.8207739 … 0.29899177 -0.35680676;;; -0.3369673 0.08685716 … 0.04711111 0.26186392; 0.09838154 0.47218075 … -0.26507103 0.06836632; -0.2230749 -0.029416293 … -0.2969591 -0.24748111; 0.25870395 -0.7325784 … 0.31196216 -0.28570586]])"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_samples = 1000\n",
    "n_points = 4\n",
    "ℓi, ℓf, ℓos = 2, 1, [1]\n",
    "total_outs = [2ℓo + 1 for ℓo in ℓos]\n",
    "\n",
    "centers = range(0f0, 3.5f0; length=4) |> collect\n",
    "c_test = CLayer((ℓi, ℓf) => ℓos, centers) |> gpu\n",
    "\n",
    "xs = rand(Float32, (n_points, 3, n_samples))\n",
    "xss = pairwise_rs(xs)\n",
    "rss = cart_to_sph(xss) |> gpu\n",
    "\n",
    "V = ones(Float32, (n_points, n_samples, 2ℓi+1)) |> gpu\n",
    "#V = ones(Float32, (1, 4))\n",
    "outs_fake = rand(Float32, (n_points, n_samples, total_outs[1])) |> gpu\n",
    "\n",
    "C_out = c_test(rss, V)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:43\u001b[39m\n"
     ]
    }
   ],
   "source": [
    "optim = Flux.setup(Flux.Adam(0.1), c_test)\n",
    "\n",
    "losses = []\n",
    "@showprogress for epoch in 1:400\n",
    "    loss, grads = Flux.withgradient(c_test) do f\n",
    "        # Evaluate model and loss inside gradient context:\n",
    "        y_hat = f(rss, V)\n",
    "        Flux.mse(y_hat[2][1], outs_fake)\n",
    "    end\n",
    "    Flux.update!(optim, c_test, grads[1])\n",
    "    push!(losses, loss)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:01\u001b[39m\n"
     ]
    }
   ],
   "source": [
    "a = (V, ([V], [V, V], []))\n",
    "\n",
    "p_test = Chain(\n",
    "            # Self interaction\n",
    "            Parallel(triv_connect, identity, Parallel(triv_connect, SILayer(1 => 2), SILayer(2 => 3), identity)),\n",
    "            # Nonlinearity\n",
    "            Parallel(triv_connect, NLLayer(2), NLLayer(3), identity)\n",
    " ) |> gpu\n",
    "\n",
    "#ou = p_test(a)[1][1]\n",
    "optim = Flux.setup(Flux.Adam(0.1), p_test)\n",
    "\n",
    "losses = []\n",
    "    @showprogress for epoch in 1:400\n",
    "    loss, grads = Flux.withgradient(p_test) do f\n",
    "        # Evaluate model and loss inside gradient context:\n",
    "        y_hat = f(a)[1][1]\n",
    "        Flux.mse(y_hat, V)\n",
    "    end;\n",
    "    Flux.update!(optim, p_test, grads[1])\n",
    "    push!(losses, loss)\n",
    "end\n",
    "\n",
    "\n",
    "#nl_test = NLLayer(1) |> gpu\n",
    "#nl_test([V]) |> typeof\n",
    "\n",
    "#combined = Tuple(vcat(x, y) for (x, y) in zip($a, $b))\n",
    "#reduce((x, y) -> (x..., y...), (a, b, c)) |> length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([1.0 1.0 … 1.0 1.0; 1.0 1.0 … 1.0 1.0; 1.0 1.0 … 1.0 1.0; 1.0 1.0 … 1.0 1.0;;; 1.0 1.0 … 1.0 1.0; 1.0 1.0 … 1.0 1.0; 1.0 1.0 … 1.0 1.0; 1.0 1.0 … 1.0 1.0;;; 1.0 1.0 … 1.0 1.0; 1.0 1.0 … 1.0 1.0; 1.0 1.0 … 1.0 1.0; 1.0 1.0 … 1.0 1.0;;; 1.0 1.0 … 1.0 1.0; 1.0 1.0 … 1.0 1.0; 1.0 1.0 … 1.0 1.0; 1.0 1.0 … 1.0 1.0;;; 1.0 1.0 … 1.0 1.0; 1.0 1.0 … 1.0 1.0; 1.0 1.0 … 1.0 1.0; 1.0 1.0 … 1.0 1.0], (CuArray{Float32, 3, CUDA.Mem.DeviceBuffer}[[0.58756787 0.58756787 … 0.58756787 0.58756787; 0.58756787 0.58756787 … 0.58756787 0.58756787; 0.58756787 0.58756787 … 0.58756787 0.58756787; 0.58756787 0.58756787 … 0.58756787 0.58756787;;; 0.58756787 0.58756787 … 0.58756787 0.58756787; 0.58756787 0.58756787 … 0.58756787 0.58756787; 0.58756787 0.58756787 … 0.58756787 0.58756787; 0.58756787 0.58756787 … 0.58756787 0.58756787;;; 0.58756787 0.58756787 … 0.58756787 0.58756787; 0.58756787 0.58756787 … 0.58756787 0.58756787; 0.58756787 0.58756787 … 0.58756787 0.58756787; 0.58756787 0.58756787 … 0.58756787 0.58756787;;; 0.58756787 0.58756787 … 0.58756787 0.58756787; 0.58756787 0.58756787 … 0.58756787 0.58756787; 0.58756787 0.58756787 … 0.58756787 0.58756787; 0.58756787 0.58756787 … 0.58756787 0.58756787;;; 0.58756787 0.58756787 … 0.58756787 0.58756787; 0.58756787 0.58756787 … 0.58756787 0.58756787; 0.58756787 0.58756787 … 0.58756787 0.58756787; 0.58756787 0.58756787 … 0.58756787 0.58756787], [-0.5641583 -0.5641583 … -0.5641583 -0.5641583; -0.5641583 -0.5641583 … -0.5641583 -0.5641583; -0.5641583 -0.5641583 … -0.5641583 -0.5641583; -0.5641583 -0.5641583 … -0.5641583 -0.5641583;;; -0.5641583 -0.5641583 … -0.5641583 -0.5641583; -0.5641583 -0.5641583 … -0.5641583 -0.5641583; -0.5641583 -0.5641583 … -0.5641583 -0.5641583; -0.5641583 -0.5641583 … -0.5641583 -0.5641583;;; -0.5641583 -0.5641583 … -0.5641583 -0.5641583; -0.5641583 -0.5641583 … -0.5641583 -0.5641583; -0.5641583 -0.5641583 … -0.5641583 -0.5641583; -0.5641583 -0.5641583 … -0.5641583 -0.5641583;;; -0.5641583 -0.5641583 … -0.5641583 -0.5641583; -0.5641583 -0.5641583 … -0.5641583 -0.5641583; -0.5641583 -0.5641583 … -0.5641583 -0.5641583; -0.5641583 -0.5641583 … -0.5641583 -0.5641583;;; -0.5641583 -0.5641583 … -0.5641583 -0.5641583; -0.5641583 -0.5641583 … -0.5641583 -0.5641583; -0.5641583 -0.5641583 … -0.5641583 -0.5641583; -0.5641583 -0.5641583 … -0.5641583 -0.5641583]], CuArray{Float32, 3, CUDA.Mem.DeviceBuffer}[[-0.14826992 -0.14826992 … -0.14826992 -0.14826992; -0.14826992 -0.14826992 … -0.14826992 -0.14826992; -0.14826992 -0.14826992 … -0.14826992 -0.14826992; -0.14826992 -0.14826992 … -0.14826992 -0.14826992;;; -0.14826992 -0.14826992 … -0.14826992 -0.14826992; -0.14826992 -0.14826992 … -0.14826992 -0.14826992; -0.14826992 -0.14826992 … -0.14826992 -0.14826992; -0.14826992 -0.14826992 … -0.14826992 -0.14826992;;; -0.14826992 -0.14826992 … -0.14826992 -0.14826992; -0.14826992 -0.14826992 … -0.14826992 -0.14826992; -0.14826992 -0.14826992 … -0.14826992 -0.14826992; -0.14826992 -0.14826992 … -0.14826992 -0.14826992;;; -0.14826992 -0.14826992 … -0.14826992 -0.14826992; -0.14826992 -0.14826992 … -0.14826992 -0.14826992; -0.14826992 -0.14826992 … -0.14826992 -0.14826992; -0.14826992 -0.14826992 … -0.14826992 -0.14826992;;; -0.14826992 -0.14826992 … -0.14826992 -0.14826992; -0.14826992 -0.14826992 … -0.14826992 -0.14826992; -0.14826992 -0.14826992 … -0.14826992 -0.14826992; -0.14826992 -0.14826992 … -0.14826992 -0.14826992], [1.0799193 1.0799193 … 1.0799193 1.0799193; 1.0799193 1.0799193 … 1.0799193 1.0799193; 1.0799193 1.0799193 … 1.0799193 1.0799193; 1.0799193 1.0799193 … 1.0799193 1.0799193;;; 1.0799193 1.0799193 … 1.0799193 1.0799193; 1.0799193 1.0799193 … 1.0799193 1.0799193; 1.0799193 1.0799193 … 1.0799193 1.0799193; 1.0799193 1.0799193 … 1.0799193 1.0799193;;; 1.0799193 1.0799193 … 1.0799193 1.0799193; 1.0799193 1.0799193 … 1.0799193 1.0799193; 1.0799193 1.0799193 … 1.0799193 1.0799193; 1.0799193 1.0799193 … 1.0799193 1.0799193;;; 1.0799193 1.0799193 … 1.0799193 1.0799193; 1.0799193 1.0799193 … 1.0799193 1.0799193; 1.0799193 1.0799193 … 1.0799193 1.0799193; 1.0799193 1.0799193 … 1.0799193 1.0799193;;; 1.0799193 1.0799193 … 1.0799193 1.0799193; 1.0799193 1.0799193 … 1.0799193 1.0799193; 1.0799193 1.0799193 … 1.0799193 1.0799193; 1.0799193 1.0799193 … 1.0799193 1.0799193], [-0.63686764 -0.63686764 … -0.63686764 -0.63686764; -0.63686764 -0.63686764 … -0.63686764 -0.63686764; -0.63686764 -0.63686764 … -0.63686764 -0.63686764; -0.63686764 -0.63686764 … -0.63686764 -0.63686764;;; -0.63686764 -0.63686764 … -0.63686764 -0.63686764; -0.63686764 -0.63686764 … -0.63686764 -0.63686764; -0.63686764 -0.63686764 … -0.63686764 -0.63686764; -0.63686764 -0.63686764 … -0.63686764 -0.63686764;;; -0.63686764 -0.63686764 … -0.63686764 -0.63686764; -0.63686764 -0.63686764 … -0.63686764 -0.63686764; -0.63686764 -0.63686764 … -0.63686764 -0.63686764; -0.63686764 -0.63686764 … -0.63686764 -0.63686764;;; -0.63686764 -0.63686764 … -0.63686764 -0.63686764; -0.63686764 -0.63686764 … -0.63686764 -0.63686764; -0.63686764 -0.63686764 … -0.63686764 -0.63686764; -0.63686764 -0.63686764 … -0.63686764 -0.63686764;;; -0.63686764 -0.63686764 … -0.63686764 -0.63686764; -0.63686764 -0.63686764 … -0.63686764 -0.63686764; -0.63686764 -0.63686764 … -0.63686764 -0.63686764; -0.63686764 -0.63686764 … -0.63686764 -0.63686764]], Any[]))"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = (V, ([V], [V, V], []))\n",
    "\n",
    "p_passenger = Chain(\n",
    "            # Self interaction\n",
    "            Parallel(triv_connect, identity, Parallel(triv_connect, SILayer(1 => 2), SILayer(2 => 3), identity))\n",
    ") |> gpu\n",
    "\n",
    "\n",
    "p_passenger(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CuArray{Float32, 3, CUDA.Mem.DeviceBuffer}[]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Vector{eltype([V])}(undef, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4-element Vector{CuArray{Float32, 3, CUDA.Mem.DeviceBuffer}}:\n",
       " [1.0 1.0 … 1.0 1.0; 1.0 1.0 … 1.0 1.0; 1.0 1.0 … 1.0 1.0; 1.0 1.0 … 1.0 1.0;;; 1.0 1.0 … 1.0 1.0; 1.0 1.0 … 1.0 1.0; 1.0 1.0 … 1.0 1.0; 1.0 1.0 … 1.0 1.0;;; 1.0 1.0 … 1.0 1.0; 1.0 1.0 … 1.0 1.0; 1.0 1.0 … 1.0 1.0; 1.0 1.0 … 1.0 1.0;;; 1.0 1.0 … 1.0 1.0; 1.0 1.0 … 1.0 1.0; 1.0 1.0 … 1.0 1.0; 1.0 1.0 … 1.0 1.0;;; 1.0 1.0 … 1.0 1.0; 1.0 1.0 … 1.0 1.0; 1.0 1.0 … 1.0 1.0; 1.0 1.0 … 1.0 1.0]\n",
       " [1.0 1.0 … 1.0 1.0; 1.0 1.0 … 1.0 1.0; 1.0 1.0 … 1.0 1.0; 1.0 1.0 … 1.0 1.0;;; 1.0 1.0 … 1.0 1.0; 1.0 1.0 … 1.0 1.0; 1.0 1.0 … 1.0 1.0; 1.0 1.0 … 1.0 1.0;;; 1.0 1.0 … 1.0 1.0; 1.0 1.0 … 1.0 1.0; 1.0 1.0 … 1.0 1.0; 1.0 1.0 … 1.0 1.0;;; 1.0 1.0 … 1.0 1.0; 1.0 1.0 … 1.0 1.0; 1.0 1.0 … 1.0 1.0; 1.0 1.0 … 1.0 1.0;;; 1.0 1.0 … 1.0 1.0; 1.0 1.0 … 1.0 1.0; 1.0 1.0 … 1.0 1.0; 1.0 1.0 … 1.0 1.0]\n",
       " [1.0 1.0 … 1.0 1.0; 1.0 1.0 … 1.0 1.0; 1.0 1.0 … 1.0 1.0; 1.0 1.0 … 1.0 1.0;;; 1.0 1.0 … 1.0 1.0; 1.0 1.0 … 1.0 1.0; 1.0 1.0 … 1.0 1.0; 1.0 1.0 … 1.0 1.0;;; 1.0 1.0 … 1.0 1.0; 1.0 1.0 … 1.0 1.0; 1.0 1.0 … 1.0 1.0; 1.0 1.0 … 1.0 1.0;;; 1.0 1.0 … 1.0 1.0; 1.0 1.0 … 1.0 1.0; 1.0 1.0 … 1.0 1.0; 1.0 1.0 … 1.0 1.0;;; 1.0 1.0 … 1.0 1.0; 1.0 1.0 … 1.0 1.0; 1.0 1.0 … 1.0 1.0; 1.0 1.0 … 1.0 1.0]\n",
       " [1.0 1.0 … 1.0 1.0; 1.0 1.0 … 1.0 1.0; 1.0 1.0 … 1.0 1.0; 1.0 1.0 … 1.0 1.0;;; 1.0 1.0 … 1.0 1.0; 1.0 1.0 … 1.0 1.0; 1.0 1.0 … 1.0 1.0; 1.0 1.0 … 1.0 1.0;;; 1.0 1.0 … 1.0 1.0; 1.0 1.0 … 1.0 1.0; 1.0 1.0 … 1.0 1.0; 1.0 1.0 … 1.0 1.0;;; 1.0 1.0 … 1.0 1.0; 1.0 1.0 … 1.0 1.0; 1.0 1.0 … 1.0 1.0; 1.0 1.0 … 1.0 1.0;;; 1.0 1.0 … 1.0 1.0; 1.0 1.0 … 1.0 1.0; 1.0 1.0 … 1.0 1.0; 1.0 1.0 … 1.0 1.0]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = ([V], [V, V], Vector{typeof(V)}(undef, 0))\n",
    "b = (Vector{typeof(V)}(undef, 0), [V], [V])\n",
    "c = ([V], [V], [V])\n",
    "\n",
    "#@btime Tuple(vcat(x, y) for (x, y) in zip($a, $b)) # Pretty fast\n",
    "\n",
    "function tuple_connect(xa, ya)\n",
    "    Tuple(vcat(x, y) for (x, y) in zip(xa, ya))\n",
    "end\n",
    "\n",
    "answer = reduce(tuple_connect, (a, b, c))\n",
    "\n",
    "answer[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4×6 CuArray{Float32, 2, CUDA.Mem.DeviceBuffer}:\n",
       "  0.298705   0.298705   0.298705  -0.331017   -0.331017   -0.331017\n",
       "  0.192269   0.192269   0.192269  -0.0233604  -0.0233604  -0.0233604\n",
       " -0.479108  -0.479108  -0.479108  -0.0682962  -0.0682962  -0.0682962\n",
       "  1.02654    1.02654    1.02654    0.583121    0.583121    0.583121"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = Parallel(hcat, Dense(1 => 4), Dense(1 => 4)) |> gpu\n",
    "d_test = Dense(1 => 4) |> gpu\n",
    "\n",
    "p_compat = (x -> p(x...))\n",
    "\n",
    "test_mat = ones(Float32, (1, 3)) |> gpu\n",
    "\n",
    "c_test = Chain(p_compat, Dense(4 => 1)) |> gpu\n",
    "\n",
    "p([test_mat, test_mat]...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parallel(\n",
       "  tuple_connect,\n",
       "  Chain(\n",
       "    var\"#534#536\"(),\n",
       "    Parallel(\n",
       "      tuple_connect,\n",
       "      CLayer(\n",
       "        FLayer(\n",
       "          RLayer{CuArray{Float32, 1, CUDA.Mem.DeviceBuffer}, Vector{Float32}, Float32}(Float32[-0.6948973, 0.8630991, -0.07906914, -0.94141114], Float32[0.0, 1.1666666, 2.3333333, 3.5], 0.875f0),  \u001b[90m# 4 parameters\u001b[39m\n",
       "        ),\n",
       "      ),\n",
       "      CLayer(\n",
       "        FLayer(\n",
       "          RLayer{CuArray{Float32, 1, CUDA.Mem.DeviceBuffer}, Vector{Float32}, Float32}(Float32[-0.38486096, 0.39335984, 0.77282935, -0.76927626], Float32[0.0, 1.1666666, 2.3333333, 3.5], 0.875f0),  \u001b[90m# 4 parameters\u001b[39m\n",
       "        ),\n",
       "      ),\n",
       "    ),\n",
       "  ),\n",
       ") "
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ℓi = 0\n",
    "ℓ_max = 1\n",
    "in_channel = []\n",
    "n_c = 2\n",
    "for (ℓf, ℓos) in [1 => [1]]\n",
    "    channel_convs = Tuple(CLayer((ℓi, ℓf) => ℓos, centers; ℓ_max = ℓ_max) for c in 1:n_c)\n",
    "\n",
    "    p = Parallel(tuple_connect, channel_convs)\n",
    "    push!(in_channel, Chain(x -> Tuple(x), p))\n",
    "    #push!(in_channel, p)\n",
    "end\n",
    "\n",
    "#in_channels[1]\n",
    "p_out = Parallel(tuple_connect, in_channel...) |> gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  18.337 ns (1 allocation: 64 bytes)\n",
      "  79.959 ns (3 allocations: 64 bytes)\n",
      "  48.077 ns (1 allocation: 32 bytes)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([0.0 0.43549958 1.0521978 0.56605774; 0.43549958 0.0 1.3980144 0.9712511; 1.0521978 1.3980144 0.0 0.8892459; 0.56605774 0.9712511 0.8892459 0.0;;; 0.0 2.3328195 1.0250881 0.37029645; 0.8087733 0.0 0.92014986 0.5493338; 2.1165047 2.2214427 0.0 1.5915178; 2.7712963 2.592259 1.5500748 0.0;;; 0.0 1.4255625 -0.7652147 -2.1712863; -1.7160301 0.0 -0.99782175 -1.8945957; 2.376378 2.143771 0.0 2.605678; 0.97030634 1.2469969 -0.53591454 0.0;;;; 0.0 0.7547935 0.6804147 0.20409416; 0.7547935 0.0 0.28264362 0.59508324; 0.6804147 0.28264362 0.0 0.5821993; 0.20409416 0.59508324 0.5821993 0.0;;; 0.0 1.5146486 1.5841296 1.1584036; 1.6269442 0.0 1.753775 1.504465; 1.557463 1.3878177 0.0 1.4140692; 1.9831891 1.6371276 1.7275236 0.0;;; 0.0 0.7300529 0.35341373 1.2074509; -2.4115398 0.0 -1.2909464 -2.5567398; -2.788179 1.8506463 0.0 -3.0358489; -1.9341418 0.584853 0.10574378 0.0;;;; 0.0 0.23809826 0.75272274 0.4063107; 0.23809826 0.0 0.8707703 0.52639395; 0.75272274 0.8707703 0.0 0.3507919; 0.4063107 0.52639395 0.3507919 0.0;;; 0.0 0.9950294 2.9156675 2.8391087; 2.1465633 0.0 3.0099263 2.9575412; 0.22592524 0.13166627 0.0 0.17008683; 0.3024839 0.18405135 2.9715059 0.0;;; 0.0 1.079581 1.6884321 1.4391255; -2.0620117 0.0 -3.065888 -2.5199015; -1.4531605 0.07570469 0.0 -0.9261585; -1.7024671 0.62169117 2.215434 0.0;;;; … ;;;; 0.0 0.46838564 0.5730394 0.44515583; 0.46838564 0.0 0.2774533 0.49560633; 0.5730394 0.2774533 0.0 0.5287956; 0.44515583 0.49560633 0.5287956 0.0;;; 0.0 1.2909136 0.85142636 1.5985639; 1.850679 0.0 0.46339047 1.8608549; 2.2901664 2.6782022 0.0 2.40003; 1.5430287 1.2807378 0.7415628 0.0;;; 0.0 -1.2235575 -0.94447887 -0.105152465; 1.9180351 0.0 0.6399502 0.9156795; 2.1971138 -2.5016425 0.0 1.0103514; 3.0364401 -2.225913 -2.1312413 0.0;;;; 0.0 0.34015885 1.0369872 0.72072834; 0.34015885 0.0 0.8899549 0.9455485; 1.0369872 0.8899549 0.0 0.9986987; 0.72072834 0.9455485 0.9986987 0.0;;; 0.0 1.42084 0.45260394 0.7071389; 1.7207527 0.0 0.13584134 1.0172312; 2.6889887 3.0057514 0.0 1.9661784; 2.4344537 2.1243615 1.1754142 0.0;;; 0.0 0.17541066 0.2479905 -2.9172206; -2.966182 0.0 0.45177037 -2.9376874; -2.8936021 -2.6898222 0.0 -2.9056003; 0.22437216 0.20390517 0.23599239 0.0;;;; 0.0 0.68959695 0.83092 0.5034629; 0.68959695 0.0 0.96320695 0.5179265; 0.83092 0.96320695 0.0 0.61538273; 0.5034629 0.5179265 0.61538273 0.0;;; 0.0 2.3549669 1.5476671 1.5956312; 0.78662586 0.0 1.0174068 0.41233674; 1.5939255 2.124186 0.0 1.6223626; 1.5459614 2.729256 1.51923 0.0;;; 0.0 1.4571805 2.7056763 1.8778843; -1.6844121 0.0 -2.9769409 -3.1160192; -0.4359163 0.16465177 0.0 0.21148917; -1.2637084 0.025573429 -2.9301035 0.0], [1.0 1.0 … 1.0 1.0; 1.0 1.0 … 1.0 1.0; 1.0 1.0 … 1.0 1.0; 1.0 1.0 … 1.0 1.0;;; 1.0 1.0 … 1.0 1.0; 1.0 1.0 … 1.0 1.0; 1.0 1.0 … 1.0 1.0; 1.0 1.0 … 1.0 1.0;;; 1.0 1.0 … 1.0 1.0; 1.0 1.0 … 1.0 1.0; 1.0 1.0 … 1.0 1.0; 1.0 1.0 … 1.0 1.0;;; 1.0 1.0 … 1.0 1.0; 1.0 1.0 … 1.0 1.0; 1.0 1.0 … 1.0 1.0; 1.0 1.0 … 1.0 1.0;;; 1.0 1.0 … 1.0 1.0; 1.0 1.0 … 1.0 1.0; 1.0 1.0 … 1.0 1.0; 1.0 1.0 … 1.0 1.0])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rss_vec = [rss]\n",
    "V_vec = [V]\n",
    "\n",
    "rss_tup = (rss,)\n",
    "V_tup = (V,)\n",
    "\n",
    "@btime vcat($rss_vec, $V_vec)\n",
    "@btime (rss_tup..., V_tup)\n",
    "@btime (rss_vec..., V_vec...)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing Increasing Dimensionality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4×4×6×5 CuArray{Float32, 4, CUDA.Mem.DeviceBuffer}:\n",
       "[:, :, 1, 1] =\n",
       " -0.0          0.00754981  -0.0499345  -0.116065\n",
       "  0.00754981  -0.0         -0.213974   -0.329704\n",
       " -0.0499345   -0.213974    -0.0         0.545569\n",
       " -0.116065    -0.329704     0.545569   -0.0\n",
       "\n",
       "[:, :, 2, 1] =\n",
       " -0.0        0.232802   0.160161    0.262934\n",
       "  0.232802  -0.0       -0.229806    0.456423\n",
       "  0.160161  -0.229806  -0.0         0.00174865\n",
       "  0.262934   0.456423   0.0017487  -0.0\n",
       "\n",
       "[:, :, 3, 1] =\n",
       " -0.0        -0.370857   0.226216    -0.0809055\n",
       " -0.370857   -0.0       -0.503037    -0.22966\n",
       "  0.226216   -0.503037  -0.0          0.00735487\n",
       " -0.0809054  -0.22966    0.00735485  -0.0\n",
       "\n",
       "[:, :, 4, 1] =\n",
       " -0.0       -0.11373     0.145963   0.258541\n",
       " -0.11373   -0.0         0.113866  -0.0867647\n",
       "  0.145963   0.113866   -0.0        0.141403\n",
       "  0.258541  -0.0867647   0.141403  -0.0\n",
       "\n",
       "[:, :, 5, 1] =\n",
       " -0.0        0.166011  -0.113239   0.15408\n",
       "  0.166011  -0.0        0.425438  -0.265191\n",
       " -0.113239   0.425438  -0.0        0.450372\n",
       "  0.15408   -0.265191   0.450372  -0.0\n",
       "\n",
       "[:, :, 6, 1] =\n",
       " -0.0        0.130746   -0.553958   -0.55348\n",
       "  0.130746  -0.0        -0.0236442   0.0446081\n",
       " -0.553958  -0.0236441  -0.0         0.104389\n",
       " -0.55348    0.0446081   0.104389   -0.0\n",
       "\n",
       "[:, :, 1, 2] =\n",
       "  0.0         0.0440398  -0.0989317  -0.343865\n",
       "  0.0440399   0.0        -0.205881   -0.484191\n",
       " -0.0989317  -0.205881    0.0         0.239383\n",
       " -0.343865   -0.484191    0.239383    0.0\n",
       "\n",
       "[:, :, 2, 2] =\n",
       "  0.0       -0.409888  -0.335243     -0.30574\n",
       " -0.409888   0.0        0.23382      -0.17016\n",
       " -0.335243   0.23382    0.0          -0.000978819\n",
       " -0.30574   -0.17016   -0.000978845   0.0\n",
       "\n",
       "[:, :, 3, 2] =\n",
       "  0.0        0.14923   -0.468468    -0.182065\n",
       "  0.14923    0.0       -0.202335    -0.174967\n",
       " -0.468468  -0.202335   0.0          0.00721453\n",
       " -0.182065  -0.174967   0.00721451   0.0\n",
       "\n",
       "[:, :, 4, 2] =\n",
       "  0.0        0.463575  -0.416647  -0.423038\n",
       "  0.463575   0.0       -0.341982   0.215508\n",
       " -0.416647  -0.341982   0.0       -0.464406\n",
       " -0.423038   0.215508  -0.464406   0.0\n",
       "\n",
       "[:, :, 5, 2] =\n",
       "  0.0       -0.177267   0.529402  -0.137167\n",
       " -0.177267   0.0       -0.224481  -0.502218\n",
       "  0.529402  -0.224481   0.0       -0.163129\n",
       " -0.137167  -0.502218  -0.163129   0.0\n",
       "\n",
       "[:, :, 6, 2] =\n",
       "  0.0       -0.3974     0.189484    0.164832\n",
       " -0.3974     0.0        0.0340704  -0.0622461\n",
       "  0.189484   0.0340704  0.0         0.124179\n",
       "  0.164831  -0.0622461  0.124179    0.0\n",
       "\n",
       "[:, :, 1, 3] =\n",
       " -0.711469  -0.643691   -0.39365   -0.388167\n",
       " -0.643691  -0.711469   -0.117377   0.0452996\n",
       " -0.39365   -0.117378   -0.711469   0.287742\n",
       " -0.388167   0.0452995   0.287742  -0.711469\n",
       "\n",
       "[:, :, 2, 3] =\n",
       " -0.711469   -0.139168   0.106601    0.0456502\n",
       " -0.139168   -0.711469   0.287216    0.296927\n",
       "  0.1066      0.287216  -0.711469    0.0970911\n",
       "  0.0456503   0.296927   0.0970912  -0.711469\n",
       "\n",
       "[:, :, 3, 3] =\n",
       " -0.711469   0.207179   -0.262908  -0.36682\n",
       "  0.207179  -0.711469    0.268988   0.0121537\n",
       " -0.262908   0.268988   -0.711469  -0.138683\n",
       " -0.36682    0.0121537  -0.138683  -0.711469\n",
       "\n",
       "[:, :, 4, 3] =\n",
       " -0.711469    0.156149  -0.0915902   0.191237\n",
       "  0.156149   -0.711469  -0.3052     -0.522433\n",
       " -0.0915902  -0.3052    -0.711469   -0.200015\n",
       "  0.191237   -0.522433  -0.200015   -0.711469\n",
       "\n",
       "[:, :, 5, 3] =\n",
       " -0.711469   -0.123787  -0.294562  -0.0683236\n",
       " -0.123786   -0.711469   0.177467  -0.229151\n",
       " -0.294562    0.177467  -0.711469   0.22338\n",
       " -0.0683236  -0.229151   0.22338   -0.711469\n",
       "\n",
       "[:, :, 6, 3] =\n",
       " -0.711469  -0.375584   0.291724   0.292187\n",
       " -0.375584  -0.711469  -0.29742   -0.282837\n",
       "  0.291724  -0.29742   -0.711469   0.34662\n",
       "  0.292187  -0.282837   0.34662   -0.711469\n",
       "\n",
       "[:, :, 1, 4] =\n",
       "  0.0       -0.194129  -0.397966  -0.267353\n",
       " -0.194129   0.0       -0.549932  -0.233488\n",
       " -0.397966  -0.549932   0.0       -0.173205\n",
       " -0.267353  -0.233488  -0.173205   0.0\n",
       "\n",
       "[:, :, 2, 4] =\n",
       " 0.0        0.279028   0.0804314  0.186386\n",
       " 0.279028   0.0        0.0512307  0.09115\n",
       " 0.0804314  0.0512307  0.0        0.504255\n",
       " 0.186386   0.09115    0.504255   0.0\n",
       "\n",
       "[:, :, 3, 4] =\n",
       "  0.0        0.326114   0.335294  -0.324459\n",
       "  0.326114   0.0       -0.14965   -0.347819\n",
       "  0.335294  -0.14965    0.0       -0.509893\n",
       " -0.324459  -0.347819  -0.509893   0.0\n",
       "\n",
       "[:, :, 4, 4] =\n",
       " 0.0        0.0543267  0.140173  0.11342\n",
       " 0.0543267  0.0        0.217843  0.406516\n",
       " 0.140173   0.217843   0.0       0.171676\n",
       " 0.11342    0.406516   0.171676  0.0\n",
       "\n",
       "[:, :, 5, 4] =\n",
       " 0.0        0.416529  0.154231   0.434218\n",
       " 0.416529   0.0       0.223743  -0.357746\n",
       " 0.154231   0.223743  0.0        0.194471\n",
       " 0.434218  -0.357746  0.194471   0.0\n",
       "\n",
       "[:, :, 6, 4] =\n",
       " 0.0       0.260907   0.162092    0.20645\n",
       " 0.260907  0.0        0.471674    0.47519\n",
       " 0.162092  0.471674   0.0        -0.0106505\n",
       " 0.20645   0.47519   -0.0106505   0.0\n",
       "\n",
       "[:, :, 1, 5] =\n",
       " -0.0        -0.0157836  -0.0942272   0.0295205\n",
       " -0.0157836  -0.0        -0.245721    0.262363\n",
       " -0.0942272  -0.245721   -0.0         0.179635\n",
       "  0.0295205   0.262363    0.179635   -0.0\n",
       "\n",
       "[:, :, 2, 5] =\n",
       " -0.0         0.0917521   0.314568   0.135509\n",
       "  0.0917521  -0.0         0.499248   0.303782\n",
       "  0.314568    0.499248   -0.0       -0.450423\n",
       "  0.135509    0.303782   -0.450423  -0.0\n",
       "\n",
       "[:, :, 3, 5] =\n",
       " -0.0        -0.320366   0.0770783  -0.0493918\n",
       " -0.320366   -0.0        0.154041   -0.170508\n",
       "  0.0770783   0.154041  -0.0        -0.259854\n",
       " -0.0493918  -0.170508  -0.259854   -0.0\n",
       "\n",
       "[:, :, 4, 5] =\n",
       " -0.0        0.478571    0.192375    0.447498\n",
       "  0.478571  -0.0         0.0531103  -0.0588345\n",
       "  0.192375   0.0531103  -0.0         0.165121\n",
       "  0.447498  -0.0588345   0.165121   -0.0\n",
       "\n",
       "[:, :, 5, 5] =\n",
       " -0.0       -0.159715     0.177854    -0.219542\n",
       " -0.159715  -0.0          0.00140014   0.0916911\n",
       "  0.177854   0.00140017  -0.0         -0.0795562\n",
       " -0.219542   0.0916911   -0.0795561   -0.0\n",
       "\n",
       "[:, :, 6, 5] =\n",
       " -0.0         0.0566532   0.0868458  -0.125663\n",
       "  0.0566532  -0.0        -0.162812   -0.167349\n",
       "  0.0868456  -0.162812   -0.0         0.60408\n",
       " -0.125663   -0.167349    0.60408    -0.0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_samples = 6\n",
    "n_points = 4\n",
    "\n",
    "xs = rand(Float32, (n_points, 3, n_samples))\n",
    "xss = pairwise_rs(xs)\n",
    "rss = cart_to_sph(xss)\n",
    "\n",
    "ℓ = 2\n",
    "Ys = generate_Yℓms(ℓ)\n",
    "yss = rand(Float32, (n_points, n_points, n_samples, 2ℓ+1))\n",
    "\n",
    "rss_gpu = rss |> gpu\n",
    "yss_gpu = yss |> gpu\n",
    "\n",
    "centers = range(0f0, 3.5f0; length=4) |> collect\n",
    "f_test = FLayer(Ys, centers) |> gpu\n",
    "\n",
    "f_test(rss_gpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:36\u001b[39m\n"
     ]
    }
   ],
   "source": [
    "optim = Flux.setup(Flux.Adam(0.01), f_test)\n",
    "\n",
    "# Testing gradient\n",
    "losses = []\n",
    "@showprogress for epoch in 1:400\n",
    "    loss, grads = Flux.withgradient(f_test) do f\n",
    "        # Evaluate model and loss inside gradient context:\n",
    "        y_hat = f(rss_gpu)\n",
    "        Flux.mse(y_hat, yss_gpu)\n",
    "    end\n",
    "    Flux.update!(optim, f_test, grads[1])\n",
    "    push!(losses, loss)\n",
    "end"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing Composition of Blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "centers = range(0f0, 3.5f0; length=4) |> collect\n",
    "\n",
    "n_samples = 100\n",
    "n_points = 4\n",
    "\n",
    "rss = rand(Float32, (n_points, 3, n_samples)) |> pairwise_rs |> cart_to_sph |> gpu\n",
    "V0 = ones(Float32, (n_points, n_samples, 1)) |> gpu\n",
    "Vrand = rand(Float32, (n_points, n_samples, 1)) |> gpu;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try implementing first parts of TFN Process\n",
    "p_chain = Chain(\n",
    "            Passenger(triv_connect, SILayer(1 => 4)),\n",
    "            E3ConvLayer([4], [[(0, 0) => [0], (0, 1) => [1]]], centers),\n",
    "            Passenger(triv_connect, SILayer(4 => 4), SILayer(4 => 4)),\n",
    "            Passenger(triv_connect, NLLayer(4), NLLayer(4)),\n",
    "            E3ConvLayer([4, 4], [[(0, 0) => [0], (0, 1) => [1]], [(1, 0) => [1], (1, 1) => [0, 1]]], centers),\n",
    "            Passenger(triv_connect, SILayer(8 => 4), SILayer(12 => 4)),\n",
    "            Passenger(triv_connect, NLLayer(4), NLLayer(4)),\n",
    "            E3ConvLayer([4, 4], [[(0, 0) => [0]], [(1, 1) => [0]]], centers),\n",
    "            Passenger(triv_connect, SILayer(8 => 4)),\n",
    "            Passenger(triv_connect, NLLayer(4)),\n",
    ") |> gpu;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([0.0 1.1618803 0.09173866 0.6294662; 1.1618803 0.0 1.1901708 0.7764151; 0.09173866 1.1901708 0.0 0.6634445; 0.6294662 0.7764151 0.6634445 0.0;;; 0.0 0.8811243 1.8064804 0.21447161; 2.2604682 0.0 2.2642 1.7315067; 1.3351122 0.87739277 0.0 0.28615603; 2.9271212 1.4100859 2.8554366 0.0;;; 0.0 -0.14347813 -1.8804499 0.08385577; 2.9981146 0.0 3.0943747 2.9587073; 1.2611427 -0.04721811 0.0 0.53937507; -3.0577369 -0.1828853 -2.6022177 0.0;;;; 0.0 0.8503873 0.5912107 1.0756193; 0.8503873 0.0 0.5026764 0.808194; 0.5912107 0.5026764 0.0 0.5323414; 1.0756193 0.808194 0.5323414 0.0;;; 0.0 2.745924 2.3553429 2.0825462; 0.39566872 0.0 0.75236124 1.2459434; 0.7862499 2.3892314 0.0 1.7770909; 1.0590465 1.8956492 1.3645017 0.0;;; 0.0 2.8689046 1.9412713 2.0071938; -0.272688 0.0 1.0725368 1.6764148; -1.2003213 -2.0690558 0.0 2.0601158; -1.1343988 -1.4651778 -1.0814768 0.0;;;; 0.0 0.52027565 0.52100843 0.45821744; 0.52027565 0.0 0.67533183 0.6109644; 0.52100843 0.67533183 0.0 0.12161232; 0.45821744 0.6109644 0.12161232 0.0;;; 0.0 2.5418851 2.2383397 2.3626688; 0.5997076 0.0 1.4117553 1.4007566; 0.903253 1.7298373 0.0 1.6001141; 0.7789239 1.740836 1.5414785 0.0;;; 0.0 1.5968108 -0.892624 -1.1263294; -1.5447818 0.0 -1.1631758 -1.3258076; 2.2489686 1.9784168 0.0 2.9091482; 2.015263 1.815785 -0.23244448 0.0;;;; … ;;;; 0.0 0.29966292 0.61443996 0.6763742; 0.29966292 0.0 0.67026573 0.79196733; 0.61443996 0.67026573 0.0 0.17784354; 0.6763742 0.79196733 0.17784354 0.0;;; 0.0 1.9249101 1.5123832 1.4995595; 1.2166827 0.0 1.3607074 1.3776029; 1.6292095 1.7808852 0.0 1.5017424; 1.6420332 1.7639897 1.6398503 0.0;;; 0.0 -2.7552598 -1.2585804 -0.9990205; 0.3863328 0.0 -0.81675345 -0.63564795; 1.8830122 2.324839 0.0 0.09250816; 2.1425722 2.5059447 -3.0490844 0.0;;;; 0.0 0.45264107 0.5354399 0.2894235; 0.45264107 0.0 0.983203 0.18649974; 0.5354399 0.983203 0.0 0.82452124; 0.2894235 0.18649974 0.82452124 0.0;;; 0.0 0.2699532 3.0517206 0.031228373; 2.8716395 0.0 2.9746072 2.4783828; 0.089872 0.16698541 0.0 0.06896254; 3.1103642 0.6632098 3.0726302 0.0;;; 0.0 0.3001123 -2.2806063 1.1315256; -2.8414803 0.0 -2.6844115 -2.8996649; 0.8609865 0.45718104 0.0 0.9035051; -2.010067 0.24192785 -2.2380877 0.0;;;; 0.0 0.96103233 0.4907514 0.91512525; 0.96103233 0.0 0.53682685 1.0319918; 0.4907514 0.53682685 0.0 0.6703862; 0.91512525 1.0319918 0.6703862 0.0;;; 0.0 1.0782038 1.4287466 2.0562007; 2.0633888 0.0 2.3705573 2.5946622; 1.712846 0.7710353 0.0 2.4046602; 1.0853918 0.5469304 0.7369326 0.0;;; 0.0 0.18644752 0.033087384 -0.4721016; -2.9551451 0.0 -2.7554474 -1.77954; -3.1085052 0.38614526 0.0 -1.0211669; 2.669491 1.3620527 2.1204257 0.0], (CuArray{Float32, 3, CUDA.Mem.DeviceBuffer}[[-0.06552795 -0.07069084 … -0.07284585 -0.070200786; -0.061040834 -0.07111011 … -0.07220268 -0.070292816; -0.06437388 -0.07471389 … -0.065686986 -0.07528475; -0.07032916 -0.069292195 … -0.07224691 -0.06677977;;;], [0.11802331 0.11750894 … 0.13836467 0.12215931; 0.10148943 0.12881343 … 0.122818336 0.1172052; 0.118275955 0.1362099 … 0.12357213 0.13417591; 0.12047246 0.121517956 … 0.13101071 0.12117564;;;], [-0.011096911 -0.017186495 … -0.00986917 -0.013550426; -0.00865708 -0.009899997 … -0.024745952 -0.017069763; -0.00722936 -0.017605614 … -0.002553131 -0.018984862; -0.015780145 -0.0122078005 … -0.019551316 -0.0045682318;;;], [0.40416327 0.45505688 … 0.5311023 0.4683804; 0.34309497 0.49300364 … 0.48645234 0.45225254; 0.39559025 0.54921514 … 0.45090863 0.5448108; 0.45551327 0.45897216 … 0.50935304 0.44415072;;;]],))"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input = (rss, ([V0],))\n",
    "input2 = (rss, ([Vrand],))\n",
    "\n",
    "p_chain(input)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trying Shape Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Tetris Shapes\n",
    "tetris = [[0 0 0; 0 0 1; 1 0 0; 1 1 0],  # chiral_shape_1\n",
    "          [0 0 0; 0 0 1; 1 0 0; 1 -1 0], # chiral_shape_2\n",
    "          [0 0 0; 1 0 0; 0 1 0; 1 1 0],  # square\n",
    "          [0 0 0; 0 0 1; 0 0 2; 0 0 3],  # line\n",
    "          [0 0 0; 0 0 1; 0 1 0; 1 0 0],  # corner\n",
    "          [0 0 0; 0 0 1; 0 0 2; 0 1 0],  # T\n",
    "          [0 0 0; 0 0 1; 0 0 2; 0 1 1],  # zigzag\n",
    "          [0 0 0; 1 0 0; 1 1 0; 2 1 0]]  # L\n",
    "\n",
    "tetris = convert.(Array{Float32, 2}, tetris)\n",
    "tetris_batched = batch(tetris)\n",
    "onehot_tetris = onehotbatch(1:length(tetris) |> collect, 1:length(tetris)) |> gpu\n",
    "Vones = ones(Float32, (size(tetris_batched, 1), size(tetris_batched, 3), 1)) |> gpu;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "sph_tetris = tetris_batched |> pairwise_rs |> cart_to_sph |> gpu;\n",
    "centers = range(0f0, 3.5f0; length=4) |> collect\n",
    "\n",
    "classifier = Chain(\n",
    "            Passenger(triv_connect, SILayer(1 => 4)),\n",
    "            E3ConvLayer([4], [[(0, 0) => [0], (0, 1) => [1]]], centers),\n",
    "            Passenger(triv_connect, SILayer(4 => 4), SILayer(4 => 4)),\n",
    "            Passenger(triv_connect, NLLayer(4), NLLayer(4)),\n",
    "            E3ConvLayer([4, 4], [[(0, 0) => [0], (0, 1) => [1]], [(1, 0) => [1], (1, 1) => [0, 1]]], centers),\n",
    "            Passenger(triv_connect, SILayer(8 => 4), SILayer(12 => 4)),\n",
    "            Passenger(triv_connect, NLLayer(4), NLLayer(4)),\n",
    "            E3ConvLayer([4, 4], [[(0, 0) => [0]], [(1, 1) => [0]]], centers),\n",
    "            Passenger(triv_connect, SILayer(8 => 4)),\n",
    "            Passenger(triv_connect, NLLayer(4)),\n",
    "            PLayer(),\n",
    "            Dense(4 => 8)\n",
    ") |> gpu;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8×8 CuArray{Float32, 2, CUDA.Mem.DeviceBuffer}:\n",
       "  0.0752553    0.0751255    0.0116361   …   0.0880927   0.0915387   0.0746019\n",
       "  0.108796     0.108508     0.0222652       0.139159    0.132958    0.111135\n",
       "  0.131753     0.131424     0.0253054       0.13741     0.151866    0.121334\n",
       "  0.00618636   0.00623168  -0.00100601      0.0234849   0.0149541   0.0144971\n",
       "  0.0307177    0.0306595    0.00672953      0.0646946   0.0473721   0.0433133\n",
       " -0.0859591   -0.0856564   -0.0253435   …  -0.0618561  -0.0921236  -0.0667383\n",
       " -0.0809994   -0.08076     -0.0193537      -0.0519535  -0.0842926  -0.0603588\n",
       "  0.146391     0.146048     0.0281436       0.128569    0.163379    0.12515"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier((sph_tetris, ([Vones],)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:01:58\u001b[39m\n"
     ]
    }
   ],
   "source": [
    "optim = Flux.setup(Flux.Adam(0.01), classifier)\n",
    "\n",
    "# Testing gradient\n",
    "losses = []\n",
    "@showprogress for epoch in 1:600\n",
    "    loss, grads = Flux.withgradient(classifier) do c\n",
    "        # Evaluate model and loss inside gradient context:\n",
    "        y_hat = c((sph_tetris, ([Vones],)))\n",
    "        Flux.logitcrossentropy(y_hat, onehot_tetris)\n",
    "    end\n",
    "    Flux.update!(optim, classifier, grads[1])\n",
    "    push!(losses, loss)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8×8 CuArray{Float32, 2, CUDA.Mem.DeviceBuffer}:\n",
       " 0.999727     0.000243681  4.11271f-5   …  6.32147f-30  1.08455f-36\n",
       " 0.000273181  0.999726     1.21361f-13     2.64894f-10  1.13664f-17\n",
       " 4.73231f-11  1.83895f-17  0.999942        0.0          0.0\n",
       " 0.0          0.0          0.0             0.0          1.22686f-23\n",
       " 4.57479f-11  1.34753f-12  1.73029f-5      0.0          0.0\n",
       " 0.0          0.0          0.0          …  2.6604f-22   6.72408f-10\n",
       " 1.46379f-18  3.07302f-5   8.95438f-26     0.999981     7.45317f-7\n",
       " 1.57f-43     1.78257f-39  0.0             1.91691f-5   0.999999"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NNlib.softmax(classifier((sph_tetris, ([Vones],))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "rotated_tetris = [(rand(RotMatrix{3, Float32}) * tet')' for tet in tetris]\n",
    "rotated_tetris_batched = batch(rotated_tetris)\n",
    "sph_rotated = rotated_tetris_batched |> pairwise_rs |> cart_to_sph |> gpu;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8×8 CuArray{Float32, 2, CUDA.Mem.DeviceBuffer}:\n",
       " 0.999727     0.000243681  4.1128f-5    …  6.3208f-30   1.08438f-36\n",
       " 0.000273179  0.999726     1.21365f-13     2.64878f-10  1.13657f-17\n",
       " 4.73249f-11  1.83901f-17  0.999942        0.0          0.0\n",
       " 0.0          0.0          0.0             0.0          1.22683f-23\n",
       " 4.57514f-11  1.3476f-12   1.73037f-5      0.0          0.0\n",
       " 0.0          0.0          0.0          …  2.66045f-22  6.72405f-10\n",
       " 1.46374f-18  3.07297f-5   8.95442f-26     0.999981     7.45306f-7\n",
       " 1.57f-43     1.78243f-39  0.0             1.91688f-5   0.999999"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final = NNlib.softmax(classifier((sph_rotated, ([Vones],))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8-element Vector{Int64}:\n",
       " 1\n",
       " 2\n",
       " 3\n",
       " 4\n",
       " 5\n",
       " 6\n",
       " 7\n",
       " 8"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "OneHotArrays.onecold(final |> cpu)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.8.4",
   "language": "julia",
   "name": "julia-1.8"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.8.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
